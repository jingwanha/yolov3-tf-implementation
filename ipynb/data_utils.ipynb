{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tif to png converting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from glob import glob\n",
    "# import pandas as pd\n",
    "# import cv2\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# load_images = glob('./raw_data/*/images/*.*')\n",
    "# load_csv = glob('./raw_data/*/*.*')\n",
    "\n",
    "# save_path = './raw_data_png/'\n",
    "\n",
    "# for img_path in tqdm(load_images):\n",
    "#     img = cv2.imread(img_path)\n",
    "    \n",
    "#     img_name = '/'.join(img_path.split('/')[-3:])[:-4]+'.png'\n",
    "#     cv2.imwrite(save_path+img_name, img)\n",
    "    \n",
    "\n",
    "# def _tif_to_csv(path): return path[:-4]+'.png' \n",
    "# for csv_path in load_csv :\n",
    "#     df =pd.read_csv(csv_path, header=None)\n",
    "#     df[0] = df[0].apply(_tif_to_csv)\n",
    "    \n",
    "#     df.to_csv(save_path + '/'.join(csv_path.split('/')[2:]),index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join('/'.join(csv_path.split('/')[:-1]), 'images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV 데이터 유효성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# csv validation 확인\n",
    "# annotation과 이미지 정보가 일치하는지 확인\n",
    "\n",
    "def csv_valid_check(csv_path):\n",
    "    print(\"label\\t\",\"n_csv\\t\",\"n_images\")\n",
    "    def _extract_img_name(path): return path.split('/')[-1]\n",
    "\n",
    "    label = csv_path.split('/')[-2]\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    images = list(map(_extract_img_name,glob(os.path.join('/'.join(csv_path.split('/')[:-1]))+'/*.jpg')))\n",
    "    csv_images = df['img_path'].unique()\n",
    "\n",
    "    print(\"{}\\t{}\\t{}\".format(label, len(csv_images), len(images)))\n",
    "    print(list(set(csv_images)^set(images)))\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "csv_path_list = glob('/home/jovyan/DATA/googlemap/google_data/*/*.csv')\n",
    "for csv_path in csv_path_list:\n",
    "    csv_valid_check(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def display_anno_samples(df_path, n_samples=5):\n",
    "    data_df = pd.read_csv(df_path,names=['img_path','x1','y1','x2','y2','label'])\n",
    "\n",
    "    images = list(data_df['img_path'].unique())\n",
    "    images = random.sample(images,n_samples)\n",
    "    \n",
    "    for img_path in images:    \n",
    "        img = cv2.imread(os.path.join('/'.join(df_path.split('/')[:-1]),img_path))\n",
    "        draw_img = img.copy()\n",
    "\n",
    "        anno_info = data_df[data_df['img_path']==img_path]\n",
    "        n_obj = len(anno_info.values)\n",
    "\n",
    "        for x1, y1, x2, y2,label in anno_info[['x1','y1','x2','y2','label']].values:\n",
    "            draw_img = cv2.rectangle(draw_img, (int(x1),int(y1)),(int(x2),int(y2)),(255,0,0),1)\n",
    "\n",
    "        print (\"number of objects : {}\".format(n_obj))\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.title(label)\n",
    "        plt.imshow(draw_img)\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "df_path = '/home/jovyan/DATA/googlemap/google_data/13/13.csv'\n",
    "display_anno_samples(df_path, n_samples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV Annotation Merge & 절대경로 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_csv_to_df(csv_path_list, save_path):\n",
    "    \n",
    "    column_names=['img_path','x1','y1','x2','y2','label']\n",
    "    merged_df = pd.DataFrame(columns=column_names)\n",
    "    \n",
    "    for csv_path in csv_path_list:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        merged_df = merged_df.append(df)\n",
    "        \n",
    "    merged_df.to_csv(save_path, index=None)\n",
    "    print(\"{} annotations from {} images are stored\".format(len(merged_df), len(merged_df['img_path'].unique())))\n",
    "\n",
    "    \n",
    "csv_path_list = glob('/home/jovyan/DATA/googlemap/google_data/*/*.csv')\n",
    "merge_csv_to_df(csv_path_list, '/home/jovyan/DATA/googlemap/google_data/label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path 절대경로 변경\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def set_abs_path(df,img_root_path, save_path):\n",
    "    anno_df = df.copy()\n",
    "    for idx, (img_path, label) in enumerate(anno_df[['img_path','label']].values):\n",
    "         anno_df['img_path'].iloc[idx] = os.path.abspath(os.path.join(img_root_path,str(label),img_path))\n",
    "    anno_df.to_csv(save_path,index=None)\n",
    "    \n",
    "data_df = pd.read_csv('/home/jovyan/DATA/googlemap/google_data/label.csv')\n",
    "set_abs_path(data_df,'/home/jovyan/DATA/googlemap/google_data/','/home/jovyan/DATA/googlemap/google_data/label_abspath.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "\n",
    "def split_dataset(df_path, test_ratio=0.2):\n",
    "    data_df = pd.read_csv(df_path)\n",
    "    split_df = data_df.copy()\n",
    "\n",
    "    labels_category = {}\n",
    "    for idx, label in enumerate(sorted(split_df['label'].unique())): labels_category[label] = idx\n",
    "\n",
    "    def set_values(row, value): return value[row]\n",
    "    split_df['category_id'] = split_df['label'].apply(set_values, args =(labels_category, ))\n",
    "    split_df['is_train'] = True\n",
    "\n",
    "    for label in sorted(data_df['label'].unique()):\n",
    "        img_path_list = list(data_df[data_df['label'] == label]['img_path'].unique())\n",
    "        test_img_path = random.sample(img_path_list,int(len(img_path_list)*test_ratio))\n",
    "        \n",
    "        for test_img in test_img_path:\n",
    "            indexes = list(data_df[data_df['img_path']==test_img].index)\n",
    "            split_df.loc[indexes,['is_train']] = False\n",
    "        \n",
    "    # check numbers\n",
    "    print(\"label\\t total\\t train\\t test\")\n",
    "    for label in sorted(data_df['label'].unique()):\n",
    "        n_total = len(data_df[data_df['label']==label])\n",
    "        n_train = len(split_df[(split_df['label']==label) & (split_df['is_train']==True)])\n",
    "        n_test = len(split_df[(split_df['label']==label) & (split_df['is_train']==False)])\n",
    "        print (\"{}\\t {}\\t {}\\t {}\".format(label, n_total, n_train, n_test))\n",
    "    \n",
    "    return split_df\n",
    "\n",
    "df_path = '/home/jovyan/DATA/googlemap/google_data/label_abspath.csv'\n",
    "split_df = split_dataset(df_path, 0.2)\n",
    "\n",
    "split_df.to_csv('/home/jovyan/DATA/googlemap/csv/label.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV annotation를 모델 학습용 데이터로 변경\n",
    "- torch_yolov3 학습 포멧으로 변경\n",
    "- tf_yolov3 학습 포멧으로 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch_yolov3 포멧\n",
    "- 이미지 당 .txt 파일을 pair로 annotation 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "def convert_anno_to_torch_yolov3(df_path, text_save_path):\n",
    "    data_df = pd.read_csv(df_path)\n",
    "    \n",
    "    labels = data_df['label'].unique()\n",
    "    mapping = {}\n",
    "    for idx, label in enumerate(sorted(labels)): mapping[label] = idx\n",
    "    \n",
    "    # directory setup\n",
    "    try : shutil.rmtree(text_save_path)\n",
    "    except: pass\n",
    "    os.mkdir(text_save_path)\n",
    "    for label in labels: os.mkdir(os.path.join(text_save_path,str(label)))\n",
    "    \n",
    "    for img_path, x1, y1, x2, y2, label,_,_ in tqdm(data_df.values):\n",
    "        img_name = img_path.split('/')[-1][:-4]\n",
    "        \n",
    "        img = cv2.imread(img_path)\n",
    "        h,w,_ = img.shape\n",
    "            \n",
    "        with open(os.path.join(text_save_path, str(label),img_name+'.txt'),'a') as f:\n",
    "            cx = ((int(x1) + int(x2)) // 2) / w\n",
    "            cy = ((int(y1) + int(y2)) // 2) / h\n",
    "            cw = (int(x2) - int(x1)) / w\n",
    "            ch = (int(y2) - int(y1)) / h\n",
    "\n",
    "            category_id = mapping[int(label)]\n",
    "\n",
    "            f.write(f\"{category_id} {cx} {cy} {cw} {ch}\\n\")\n",
    "\n",
    "            \n",
    "# 저장 폴더 디렉토리 생성\n",
    "df_path = '/home/jovyan/DATA/googlemap/csv/label.csv'\n",
    "text_save_path = '/home/jovyan/DATA/googlemap/torch/labels' # './format_data/torch_yolov3/labels'\n",
    "convert_anno_to_torch_yolov3(df_path, text_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_txt_annotation(df_path, text_save_path):\n",
    "    # csv와 txt의 annotation 갯수 확인\n",
    "    data_df = pd.read_csv(df_path)\n",
    "    labels = sorted(data_df['label'].unique())\n",
    "\n",
    "    print(\"label\\t n_csv\\t n_txt\")\n",
    "    for label in labels:\n",
    "        txt_files = glob(os.path.join(text_save_path, str(label))+'/*.*')\n",
    "        n_txt_anno = 0    \n",
    "\n",
    "        for txt_path in txt_files: \n",
    "            f_name = txt_path.split('/')[-1][:-4]\n",
    "\n",
    "            with open(txt_path,'r') as f :\n",
    "                lines = f.readlines()\n",
    "                n_txt_anno +=len(lines)\n",
    "\n",
    "        print(\"{}\\t {}\\t {}\\t\".format(label,len(data_df[data_df['label']==label]), n_txt_anno))\n",
    "    \n",
    "valid_txt_annotation(df_path, text_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def save_train_test_set(df_path, save_root_path, anno_txt_path):\n",
    "    data_df = pd.read_csv(df_path)\n",
    "\n",
    "    # directory setup\n",
    "    try : shutil.rmtree(save_root_path)\n",
    "    except: pass\n",
    "    os.mkdir(save_root_path)\n",
    "    os.mkdir(os.path.join(save_root_path,'train'))\n",
    "    os.mkdir(os.path.join(save_root_path,'train','images'))\n",
    "    os.mkdir(os.path.join(save_root_path,'train','labels'))\n",
    "    os.mkdir(os.path.join(save_root_path,'test'))\n",
    "    os.mkdir(os.path.join(save_root_path,'test','images'))\n",
    "    os.mkdir(os.path.join(save_root_path,'test','labels'))\n",
    "\n",
    "    for img_path in data_df['img_path'].unique():\n",
    "        f_name = img_path.split('/')[-1]\n",
    "\n",
    "        is_train = data_df[data_df['img_path']==img_path]['is_train'].unique()[0]\n",
    "        label = data_df[data_df['img_path']==img_path]['label'].unique()[0]\n",
    "\n",
    "        txt_path = os.path.join(anno_txt_path,str(label),f_name[:-4]+'.txt')\n",
    "\n",
    "        if is_train : save_path = os.path.join(save_root_path,'train')\n",
    "        else: save_path = os.path.join(save_root_path,'test')\n",
    "\n",
    "        shutil.copy(txt_path, os.path.join(save_path,'labels',f_name[:-4]+'.txt'))\n",
    "        shutil.copy(img_path, os.path.join(save_path,'images',f_name))    \n",
    "        \n",
    "df_path = '/home/jovyan/DATA/googlemap/csv/label.csv'\n",
    "save_root_path = '/home/jovyan/DATA/googlemap/torch/data/'\n",
    "anno_txt_path = '/home/jovyan/DATA/googlemap/torch/labels/'\n",
    "save_train_test_set(df_path, save_root_path, anno_txt_path)\n",
    "\n",
    "print(\"train images : \",len(glob('/home/jovyan/DATA/googlemap/torch/data/train/images/*.*')))\n",
    "print(\"test images : \",len(glob('/home/jovyan/DATA/googlemap/torch/data/test/images/*.*')))\n",
    "\n",
    "print(\"train annotations : \",len(glob('/home/jovyan/DATA/googlemap/torch/data/train/labels/*.*')))\n",
    "print(\"test annotations : \",len(glob('/home/jovyan/DATA/googlemap/torch/data/test/labels/*.*')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf_yolov3 포멧\n",
    "- tfrecord로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_tf_features(anno_df,img_shape):\n",
    "    img_path = anno_df['img_path'].unique()\n",
    "    if len(img_path) > 1: return warnings.warn(\"Image annotation is wrong\")\n",
    "    \n",
    "    img_raw = open(img_path[0], 'rb').read()\n",
    "    xmin = []\n",
    "    ymin = []\n",
    "    xmax = []\n",
    "    ymax = []\n",
    "    classes_text = []\n",
    "    height,width = img_shape\n",
    "\n",
    "    for x1,y1,x2,y2,label in anno_df[['x1','y1','x2','y2','label']].values:\n",
    "        xmin.append(float(x1) / width)\n",
    "        ymin.append(float(y1) / height)\n",
    "        xmax.append(float(x2) / width)\n",
    "        ymax.append(float(y2) / height)\n",
    "        \n",
    "        classes_text.append(str(label).encode('utf8'))\n",
    "        \n",
    "\n",
    "    features={\n",
    "        'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),\n",
    "        'image/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_path[0].encode('utf8')])),\n",
    "        'image/object/bbox/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=xmin)),\n",
    "        'image/object/bbox/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=xmax)),\n",
    "        'image/object/bbox/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=ymin)),\n",
    "        'image/object/bbox/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=ymax)),\n",
    "        'image/object/class/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\n",
    "        }\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "    \n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_tfrecord_from_csv(data_df, output_path):\n",
    "    writer = tf.io.TFRecordWriter(output_path)\n",
    "    img_list = data_df['img_path'].unique()\n",
    "    \n",
    "    for img_path in tqdm(img_list):\n",
    "        img = cv2.imread(img_path)\n",
    "        df = data_df[data_df['img_path']==img_path]\n",
    "        \n",
    "        tfrecord_example = _set_tf_features(df,img.shape[:2])\n",
    "        writer.write(tfrecord_example.SerializeToString())\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = '/home/jovyan/DATA/googlemap/csv/label.csv'\n",
    "\n",
    "train_df = df[df['is_train']==True].copy()\n",
    "test_df = df[df['is_train']==False].copy()\n",
    "\n",
    "create_tfrecord_from_csv(train_df, '/home/jovyan/DATA/googlemap/tfrecord/train2.tfrecord')\n",
    "create_tfrecord_from_csv(test_df, '/home/jovyan/DATA/googlemap/tfrecord/test2.tfrecord')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_coco(anno_df, destfile):\n",
    "\n",
    "    anno_df[\"label\"] = anno_df[\"label\"].astype(str)\n",
    "    \n",
    "    \n",
    "    label_names = list(anno_df['label'].unique())\n",
    "    label_names = [str(x) for x in label_names]\n",
    "    \n",
    "    label_categories = {}\n",
    "    \n",
    "    # label 별 ID 부여\n",
    "    for label in label_names:\n",
    "        label_categories[label] = int(anno_df[anno_df[\"label\"]==label]['category_id'].unique()[0])\n",
    "    \n",
    "    data_dict = {}\n",
    "    data_dict['images'] = []\n",
    "    data_dict['categories'] = []\n",
    "    data_dict['annotations'] = []\n",
    "    \n",
    "    for idx, name in enumerate(label_names):\n",
    "        single_category = {'id': label_categories[name], 'name': name, 'supercategory': name}\n",
    "        data_dict['categories'].append(single_category)\n",
    "\n",
    "    inst_count = 1\n",
    "    image_id = 1\n",
    "    \n",
    "    with open(destfile, 'w') as f_out:\n",
    "        images = list(anno_df['img_path'].unique())\n",
    "        \n",
    "        for image_path in tqdm(images): \n",
    "            img_name = image_path.split('/')[-1]\n",
    "            \n",
    "            img = cv2.imread(image_path)\n",
    "            height, width, _  = img.shape\n",
    "\n",
    "            single_image = {}\n",
    "            single_image['file_name'] = img_name\n",
    "            single_image['id'] = image_id\n",
    "            single_image['width'] = width\n",
    "            single_image['height'] = height\n",
    "            data_dict['images'].append(single_image)\n",
    "\n",
    "            # annotations\n",
    "            objects = anno_df[anno_df['img_path']==image_path]\n",
    "        \n",
    "            for x1, y1, x2, y2,label in objects[[\"x1\", \"y1\", \"x2\", \"y2\",\"label\"]].values:\n",
    "                single_obj = {}\n",
    "\n",
    "                single_obj['category_id'] = label_categories[label]\n",
    "\n",
    "                width, height = x2-x1, y2-y1\n",
    "                \n",
    "                single_obj['bbox'] = x1, y1, width, height\n",
    "                single_obj['area'] = width*height\n",
    "                \n",
    "                single_obj['image_id'] = image_id\n",
    "                \n",
    "                single_obj['iscrowd'] = 0\n",
    "                single_obj['ignore'] = 0\n",
    "                \n",
    "                data_dict['annotations'].append(single_obj)\n",
    "                single_obj['id'] = inst_count\n",
    "                inst_count = inst_count + 1\n",
    "            image_id = image_id + 1\n",
    "            \n",
    "        json.dump(data_dict, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_df = pd.read_csv('/home/jovyan/DATA/googlemap/csv/label.csv')\n",
    "\n",
    "data_to_coco(anno_df[anno_df['is_train']==True], '/home/jovyan/DATA/googlemap/coco/train.json')\n",
    "data_to_coco(anno_df[anno_df['is_train']==False], '/home/jovyan/DATA/googlemap/coco/test.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
